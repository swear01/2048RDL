# -*- coding: utf-8 -*-
"""2048-RDL V1.0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1o6i4kr-uNBPLmKdjSS7jR-a3dRtTpavI
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
#drive.mount('/content/drive')
!pip install stable-baselines[mpi]==2.10
# %tensorflow_version 1.x
import random
import copy 
import gym 
import numpy
import stable_baselines

#part is copy from google project ;
# 0 left counterclockwise
N = 4 ;
class Board:
    def __init__(self):
        self.board = [[0] * N for i in range(N)] ;
        self.score = 0 ;
        self.over = False ;
        self.randomTile()
        self.randomTile()

    def rotateLeft(self, grid):
        out = self.emptyGrid()
        for c in range(4):
            for r in range(4):
                out[r][3-c] = grid[c][r] ;
        return out

    def rotateRight(self, grid):
        out = self.emptyGrid()
        for c in range(4):
            for r in range(4):
                out[3-r][c] = grid[c][r] ;
        return out

    def emptyGrid(self):
        out = list()
        for x in range(4):
            col = list()
            for y in range(4):
                col.append(0)
            out.append(col)
        return out

    def get_empty_cells(self):
        out = list() ;
        for i in range(N):
            for j in range(N):
                if self.board[i][j] == 0:
                    out.append((i,j)) ;
        return out ;

    def randomTile(self):
        cells = self.get_empty_cells()
        if not cells: return False
        #print 'cells', cells

        if random.random() < 0.9: v = 1 ;
        else: v = 2 ;

        cid = random.choice(cells)
        #print cid
        self.board[cid[0]][cid[1]] = v
        return True

    def show(self):
        for i in self.board:
            print(i) ;
        print(self.score) ;

    def gameover(self):
        if self.over : return True ;
        over = True ;
        for row in range(4):
            for column in range (4):
                if self.board[row][column] == 0 :
                    over = False ;
        #if not over : return False ;
        for row in range(4):
            for column in range(3):
                if self.board[row][column] == self.board[row][column+1] :
                    over = False ;
        for row in range(3):
            for column in range(4):
                if self.board[row][column] == self.board[row+1][column] :
                    over = False ;
        if over : self.over = True ;
        return over 

    def move(self, direction):
        score, grid = self.to_move(self.board, direction)
    
        #self.board = next_board ;
        if grid != self.board: #moved
            self.board = grid ;
            self.randomTile() ;
        else :
            self.over = True ;
            score -= 30 ;
        self.score += score ;
        return score ;
        

    def to_move(self, grid2, direction):
        #out = self.emptyGrid()
        # left is 0
        grid = copy.deepcopy(grid2) ;
        for i in range(direction):
            grid = self.rotateLeft(grid) ;
        score = 0 ;
        for row in range(4):
            for i in range(3,0,-1):
                for j in range(i):
                    if grid[row][j] == 0 :
                        grid[row][j], grid[row][j+1] = grid[row][j+1], grid[row][j] ;
            for column in range(3):
                if grid[row][column] == grid[row][column+1] and grid[row][column] != 0:
                    score += 2**grid[row][column] ;
                    grid[row][column]+=1 ;
                    grid[row][column+1] = 0 ;
            for i in range(3,0,-1):
                for j in range(i):
                    if grid[row][j] == 0 :
                        grid[row][j], grid[row][j+1] = grid[row][j+1], grid[row][j] ;
                        #print("I swap") ;

        for i in range(direction):
            grid = self.rotateRight(grid) ;
        #for row in grid : print(row) ;
        return score, grid ;

class myEnv(gym.Env):
    observation_space= gym.spaces.MultiDiscrete([15]*16) #needed! to input and output
    action_space = gym.spaces.Discrete(4) ;
    def __init__(self):
        super(myEnv, self).__init__()
        self.game = Board() ;

    #def _seed(self, seed=None):
    #    self.np_random, seed = seeding.np_random(seed)
    #    return [seed]

    def step(self,direction):
        score = self.game.move(direction) ;
        return (numpy.array(self.game.board).flatten(),self.game.score,self.game.gameover(),0) ; #( observation, reward, done, info )

    def reset(self):
        self.game.over = False ;
        self.game.board = self.game.emptyGrid() ;
        self.game.score = 0 ;
        self.game.randomTile()
        self.game.randomTile()
        return numpy.array(self.game.board).flatten() ;
    def render(self, mode='human'):
        if mode == 'human':
            self.game.show() ;
        else:
            super(MyEnv, self).render(mode=mode) # just raise an exception
    def seed(self):
        random.seed() ;

import gym
from random import randint

env = myEnv() ;

# The reset method is called at the beginning of an episode
obs = env.reset()

score , grid, over, info = env.step(randint(0,4))
print(score, grid)

#from stable_baselines.common.env_checker import check_env
#env = myEnv() ;
#stable_baselines.common.env_checker.check_env(env)

env = myEnv() ;
model = stable_baselines.PPO1("MlpPolicy", env, verbose=1)

model.learn(total_timesteps=50000) ;

obs = env.reset()
n_steps = 100
for step in range(n_steps):
  action, _ = model.predict(obs, deterministic=True)
  #print("Step {}".format(step + 1))
  print("Action: ", action)
  obs, reward, done, info = env.step(action)
  print('obs=', obs, 'reward=', reward, 'done=', done)
  #env.render(mode='console')
  if done:
    # Note that the VecEnv resets automatically
    # when a done signal is encountered
    break
print("Goal reached!", "reward=", env.game.score)
env.game.show() ;